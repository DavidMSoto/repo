featureEngrg <- function(data) {
head(data$PassengerId, n = 1L)
## Using Fate ILO Survived because term is shorter and just sounds good
##data$Fate <- data$Survived
## Revaluing Fate factor to ease assessment of confusion matrices later
##data$Fate <- revalue(data$Fate, c("1" = "Survived", "0" = "Perished"))
## Boat.dibs attempts to capture the "women and children first"
## policy in one feature.  Assuming all females plus males under 15
## got "dibs' on access to a lifeboat
data$Boat.dibs <- "No"
data$Boat.dibs[which(data$Sex == "female" | data$Age < 15)] <- "Yes"
data$Boat.dibs <- as.factor(data$Boat.dibs)
## Family consolidates siblings and spouses (SibSp) plus
## parents and children (Parch) into one feature
data$Family <- data$SibSp + data$Parch
## Fare.pp attempts to adjust group purchases by size of family
data$Fare.pp <- data$Fare/(data$Family + 1)
## Giving the traveling class feature a new look
data$Class <- data$Pclass
data$Class <- revalue(data$Class,
c("1"="First", "2"="Second", "3"="Third"))
## First character in Cabin number represents the Deck
data$Deck <- substring(data$Cabin, 1, 1)
data$Deck[ which( is.na(data$Deck ))] <- "UNK"
data$Deck <- as.factor(data$Deck)
## Odd-numbered cabins were reportedly on the port side of the ship
## Even-numbered cabins assigned Side="starboard"
data$cabin.last.digit <- str_sub(data$Cabin, -1)
data$Side <- "UNK"
data$Side[which(isEven(data$cabin.last.digit))] <- "port"
data$Side[which(isOdd(data$cabin.last.digit))] <- "starboard"
data$Side <- as.factor(data$Side)
data$cabin.last.digit <- NULL
return (data)
}
## add remaining features to training data frame
df.train <- featureEngrg(df.train)
train.keeps <- c("Survived", "Sex", "Boat.dibs", "Age", "Title", "Class", "Deck", "Side", "Fare", "Fare.pp", "Embarked", "Family", "FamilySize")
df.train.munged <- df.train[train.keeps]
require(caret)
set.seed(23)
training.rows <- createDataPartition(df.train.munged$Survived,  p = 0.8, list = FALSE) # *** changed
## split training data into train batch and test batch
train.batch <- df.train.munged[training.rows, ]
test.batch <- df.train.munged[-training.rows, ]
modelaccuracy <- function(test, rpred) {
result_1 <- test$Survived == rpred
sum(result_1) / length(rpred)
}
checkaccuracy <- function(accuracy) {
if (accuracy > bestaccuracy) {
bestaccuracy <- accuracy
assign("bestaccuracy", accuracy, envir = .GlobalEnv)
label <- 'better'
} else if (accuracy < bestaccuracy) {
label <- 'worse'
} else {
label <- 'no change'
}
label
}
library(rpart)
# starting with Age and Sex as indicators
fol <- formula(Survived ~ Age + Sex)						# 0.845
rmodel <- rpart(fol, method="class", data=train.batch)
rpred <- predict(rmodel, newdata=test.batch, type="class")
accuracy <- modelaccuracy(test.batch, rpred)
bestaccuracy <- accuracy # init base accuracy
print(c("accuracy1", accuracy))								# baseline
fol <- formula(Survived ~ Age + Sex + Class)				# 0.838
rmodel <- rpart(fol, method="class", data=train.batch)
rpred <- predict(rmodel, newdata=test.batch, type="class")
accuracy <- modelaccuracy(test.batch, rpred)
accuracyLabel <- checkaccuracy(accuracy)
# almost as good but little worse
print(c("accuracy2", accuracy, accuracyLabel))				# no change
fol <- formula(Survived ~ Age + Sex + Fare.pp)					# 0.807
rmodel <- rpart(fol, method="class", data=train.batch)
rpred <- predict(rmodel, newdata=test.batch, type="class")
accuracy <- modelaccuracy(test.batch, rpred)
accuracyLabel <- checkaccuracy(accuracy)
print(c("accuracy3", accuracy, accuracyLabel))				# worse
fol <- formula(Survived ~ Class + I(Title=="Mr") + I(Title=="Jonkheer")  + Age +
Family + I(Embarked=="S")  + I(Title=="Mr"&Class=="Third"))
rmodel <- rpart(fol, method="class", data=train.batch)
rpred <- predict(rmodel, newdata=test.batch, type="class")
accuracy <- modelaccuracy(test.batch, rpred)
accuracyLabel <- checkaccuracy(accuracy)
print(c("accuracy3", accuracy, accuracyLabel))				# worse
fol <- formula(Survived ~ Class + I(Title=="Mr") + I(Title=="Jonkheer")  + Age +
Family + I(Embarked=="S")  + I(Title=="Mr"&Class=="Third") + FamilySize)
rmodel <- rpart(fol, method="class", data=train.batch)
rpred <- predict(rmodel, newdata=test.batch, type="class")
accuracy <- modelaccuracy(test.batch, rpred)
accuracyLabel <- checkaccuracy(accuracy)
print(c("accuracy3", accuracy, accuracyLabel))				# worse
fol <- formula(Survived ~ Age + Sex + Pclass + FamilySizeAdj )
rmodel <- rpart(fol, method="class", data=train.batch)
rpred <- predict(rmodel, newdata=test.batch, type="class")
accuracy <- modelaccuracy(test.batch, rpred)
accuracyLabel <- checkaccuracy(accuracy)
print(c("accuracy3", accuracy, accuracyLabel))				# worse
fol <- formula(Survived ~ Age + Sex + Class + FamilySizeAdj )
rmodel <- rpart(fol, method="class", data=train.batch)
rpred <- predict(rmodel, newdata=test.batch, type="class")
accuracy <- modelaccuracy(test.batch, rpred)
accuracyLabel <- checkaccuracy(accuracy)
print(c("accuracy3", accuracy, accuracyLabel))				# worse
train.keeps <- c("Survived", "Sex", "Boat.dibs", "Age", "Title", "Class", "Deck",
"Side", "Fare", "Fare.pp", "Embarked", "Family", "FamilySize", "FamilySizeAdj")
df.train.munged <- df.train[train.keeps]
set.seed(23)
training.rows <- createDataPartition(df.train.munged$Survived,  p = 0.8, list = FALSE) # *** changed
## split training data into train batch and test batch
train.batch <- df.train.munged[training.rows, ]
test.batch <- df.train.munged[-training.rows, ]
fol <- formula(Survived ~ Age + Sex + Class + FamilySizeAdj )
rmodel <- rpart(fol, method="class", data=train.batch)
rpred <- predict(rmodel, newdata=test.batch, type="class")
accuracy <- modelaccuracy(test.batch, rpred)
accuracyLabel <- checkaccuracy(accuracy)
print(c("accuracy3", accuracy, accuracyLabel))				# worse
fol <- formula(Survived ~ Age + Sex  + FamilySizeAdj )
rmodel <- rpart(fol, method="class", data=train.batch)
rpred <- predict(rmodel, newdata=test.batch, type="class")
accuracy <- modelaccuracy(test.batch, rpred)
accuracyLabel <- checkaccuracy(accuracy)
print(c("accuracy3", accuracy, accuracyLabel))				# worse
fol <- formula(Survived ~ Age + Sex  + FamilySizeAdj + I(Title=="Mr"&Class=="Third") )
rmodel <- rpart(fol, method="class", data=train.batch)
rpred <- predict(rmodel, newdata=test.batch, type="class")
accuracy <- modelaccuracy(test.batch, rpred)
accuracyLabel <- checkaccuracy(accuracy)
print(c("accuracy3", accuracy, accuracyLabel))				# worse
fol <- formula(Survived ~ Age + Sex  + FamilySizeAdj + I(Title=="Jonkheer"&Class=="Third") )
rmodel <- rpart(fol, method="class", data=train.batch)
rpred <- predict(rmodel, newdata=test.batch, type="class")
accuracy <- modelaccuracy(test.batch, rpred)
accuracyLabel <- checkaccuracy(accuracy)
print(c("accuracy3", accuracy, accuracyLabel))				# worse
fol <- formula(Survived ~ Age + Sex + Fare.pp)					# 0.807
rmodel <- rpart(fol, method="class", data=train.batch)
rpred <- predict(rmodel, newdata=test.batch, type="class")
accuracy <- modelaccuracy(test.batch, rpred)
accuracyLabel <- checkaccuracy(accuracy)
print(c("accuracy3", accuracy, accuracyLabel))				# worse
fol <- formula(Survived ~ Class + I(Title=="Mr") + I(Title=="Jonkheer")  + Age +
Family + I(Embarked=="S")  + I(Title=="Mr"&Class=="Third"))
rmodel <- rpart(fol, method="class", data=train.batch)
rpred <- predict(rmodel, newdata=test.batch, type="class")
accuracy <- modelaccuracy(test.batch, rpred)
accuracyLabel <- checkaccuracy(accuracy)
print(c("accuracy3", accuracy, accuracyLabel))				# worse
Titanic.logit.1 <- glm(Fate ~ Sex + Class + Age + Family + Embarked + Fare,
data = train.batch, family=binomial("logit"))
Titanic.logit.1 <- glm(Survived ~ Sex + Class + Age + Family + Embarked + Fare,
data = train.batch, family=binomial("logit"))
rpred <- predict(Titanic.logit.1 , newdata=test.batch, type="class")
rmodel <- rpart(fol, method="class", data=train.batch)
rpred <- predict(rmodel, newdata=test.batch, type="class")
accuracy <- modelaccuracy(test.batch, rpred)
accuracyLabel <- checkaccuracy(accuracy)
print(c("accuracy3", accuracy, accuracyLabel))				# worse
rmodel
anova(Titanic.logit.1, test="Chisq")
fol <- formula(Survived ~ Age + Sex  + FamilySizeAdj + I(Title=="Jonkheer"&Class=="Third") )
rmodel <- rpart(fol, method="class", data=train.batch)
anova(rmodel, test="Chisq")
Titanic.logit.1 <- glm(Survived ~ Sex + Class + Age + Family + Embarked + Fare,
data = train.batch, family=binomial("logit"))
anova(Titanic.logit.1, test="Chisq")
Titanic.logit.1 <- glm(Survived ~ Sex + Class + Age + Family + Embarked + Fare + FamilySizeAdj +FamilySize,
data = train.batch, family=binomial("logit"))
anova(Titanic.logit.1, test="Chisq")
Chisq <- anova(Titanic.logit.1, test="Chisq")
View(Chisq)
accuracy <- modelaccuracy(test.batch, Chisq)
View(modelaccuracy)
anova(Titanic.logit.2, test="Chisq")
tc <- trainControl("cv",10)
rpart.grid <- expand.grid(.cp=0.2)
(train.rpart <- train(Survived ~., data=train.batch, method="rpart",trControl=tc,tuneGrid=rpart.grid))
(train.rpart <- train(Survived ~., data=test.batch, method="rpart",trControl=tc,tuneGrid=rpart.grid))
(train.rpart <- train(Survived ~ Age + Sex  + FamilySizeAdj + I(Title=="Jonkheer"&Class=="Third")
, data=test.batch, method="rpart",trControl=tc,tuneGrid=rpart.grid))
(train.rpart <- train(Survived ~., data=test.batch, method="rpart",trControl=tc,tuneGrid=rpart.grid))
(train.rpart <- train(Survived ~ Age + Sex   + I(Title=="Jonkheer"&Class=="Third")
, data=test.batch, method="rpart",trControl=tc,tuneGrid=rpart.grid))
(train.rpart <- train(Survived ~., data=test.batch, method="rpart",trControl=tc,tuneGrid=rpart.grid))
(train.rpart <- train(Survived ~ Age + Sex   + I(Title=="Jonkheer"&Class=="Third")
, data=test.batch, method="rpart",trControl=tc,tuneGrid=rpart.grid))
(train.rpart <- train(Survived ~., data=test.batch, method="rpart",trControl=tc,tuneGrid=rpart.grid))
(train.rpart <- train(Survived ~ Age + Sex  + FamilySize + I(Title=="Jonkheer"&Class=="Third")
, data=test.batch, method="rpart",trControl=tc,tuneGrid=rpart.grid))
tc <- trainControl(method = "repeatedcv", repeats = 10,
summaryFunction = twoClassSummary,
classProbs = TRUE)
rpart.grid <- expand.grid(.cp=0.2)
(train.rpart <- train(Survived ~ Age + Sex  + FamilySize + I(Title=="Jonkheer"&Class=="Third")
, data=test.batch, method="rpart",trControl=tc,tuneGrid=rpart.grid))
(train.rpart <- train(Survived ~ Age + Sex  + FamilySize
, data=test.batch, method="rpart",trControl=tc,tuneGrid=rpart.grid))
(train.rpart <- train(Survived ~., data=test.batch, method="rpart",trControl=tc,tuneGrid=rpart.grid))
tc <- trainControl("cv",10)
(train.rpart <- train(Survived ~., data=test.batch, method="rpart",trControl=tc,tuneGrid=rpart.grid))
(train.rpart <- train(Survived ~., data=train.batch, method="rpart",trControl=tc,tuneGrid=rpart.grid))
glm.tune.5 <- train(Fate ~ Class + I(Title=="Mr") + I(Title=="Jonkheer")
+ Age + Family + I(Embarked=="S")
+ I(Title=="Mr"&Class=="Third"),
data = train.batch,
method = "glm", metric = "ROC",
trControl = cv.ctrl)
summary(glm.tune.5)
table(df.train$Sex, df.train$Title)
# Load packages
rm(list = ls())
library('ggplot2') # visualization
library('ggthemes') # visualization
library('scales') # visualization
library('dplyr') # data manipulation
library('mice') # imputation
library('randomForest') # classification algorithm
train <- read.csv('../input/train.csv', stringsAsFactors = F)
test  <- read.csv('../input/test.csv', stringsAsFactors = F)
full  <- bind_rows(train, test) # bind training & test data
# check data
str(full)
full$Title <- gsub('(.*, )|(\\..*)', '', full$Name)
table(full$Sex, full$Title)
rare_title <- c('Dona', 'Lady', 'the Countess','Capt', 'Col', 'Don',
'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer')
table(full$Sex, full$Title)
# Also reassign mlle, ms, and mme accordingly
full$Title[full$Title == 'Mlle']        <- 'Miss'
full$Title[full$Title == 'Ms']          <- 'Miss'
full$Title[full$Title == 'Mme']         <- 'Mrs'
full$Title[full$Title %in% rare_title]  <- 'Rare Title'
table(full$Sex, full$Title)
full$Surname <- sapply(full$Name,
function(x) strsplit(x, split = '[,.]')[[1]][1])
cat(paste('We have <b>', nlevels(factor(full$Surname)), '</b> unique surnames. I would be interested to infer ethnicity based on surname --- another time.'))
# Create a family size variable including the passenger themselves
full$Fsize <- full$SibSp + full$Parch + 1
# Create a family variable
full$Family <- paste(full$Surname, full$Fsize, sep='_')
# Use ggplot2 to visualize the relationship between family size & survival
ggplot(full[1:891,], aes(x = Fsize, fill = factor(Survived))) +
geom_bar(stat='count', position='dodge') +
scale_x_continuous(breaks=c(1:11)) +
labs(x = 'Family Size') +
theme_few()
ggplot(full[1:891,], aes(x = Fsize, fill = factor(Survived))) +
geom_bar(stat='count', position='dodge') +
scale_x_continuous(breaks=c(1:11)) +
labs(x = 'Family Size') +
theme_few()
full$FsizeD[full$Fsize == 1] <- 'singleton'
full$FsizeD[full$Fsize < 5 & full$Fsize > 1] <- 'small'
full$FsizeD[full$Fsize > 4] <- 'large'
# Show family size by survival using a mosaic plot
mosaicplot(table(full$FsizeD, full$Survived), main='Family Size by Survival', shade=TRUE)
# Discretize family size
full$FsizeD[full$Fsize == 1] <- 'singleton'
full$FsizeD[full$Fsize < 5 & full$Fsize > 1] <- 'small'
full$FsizeD[full$Fsize > 4] <- 'large'
# Show family size by survival using a mosaic plot
mosaicplot(table(full$FsizeD, full$Survived), main='Family Size by Survival', shade=TRUE)
# Use ggplot2 to visualize the relationship between family size & survival
ggplot(full[1:891,], aes(x = Fsize, fill = factor(Survived))) +
geom_bar(stat='count', position='dodge') +
scale_x_continuous(breaks=c(1:11)) +
labs(x = 'Family Size') +
theme_few()
# Discretize family size
full$FsizeD[full$Fsize == 1] <- 'singleton'
full$FsizeD[full$Fsize < 5 & full$Fsize > 1] <- 'small'
full$FsizeD[full$Fsize > 4] <- 'large'
# Show family size by survival using a mosaic plot
mosaicplot(table(full$FsizeD, full$Survived), main='Family Size by Survival', shade=TRUE)
# This variable appears to have a lot of missing values
full$Cabin[1:28]
# The first character is the deck. For example:
strsplit(full$Cabin[2], NULL)[[1]]
# Create a Deck variable. Get passenger deck A - F:
full$Deck<-factor(sapply(full$Cabin, function(x) strsplit(x, NULL)[[1]][1]))
full$Deck
# Passengers 62 and 830 are missing Embarkment
full[c(62, 830), 'Embarked']
cat(paste('We will infer their values for **embarkment** based on present data that we can imagine may be relevant: **passenger class** and **fare**. We see that they paid<b> $', full[c(62, 830), 'Fare'][[1]][1], '</b>and<b> $', full[c(62, 830), 'Fare'][[1]][2], '</b>respectively and their classes are<b>', full[c(62, 830), 'Pclass'][[1]][1], '</b>and<b>', full[c(62, 830), 'Pclass'][[1]][2], '</b>. So from where did they embark?'))
# Get rid of our missing passenger IDs
embark_fare <- full %>%
filter(PassengerId != 62 & PassengerId != 830)
# Use ggplot2 to visualize embarkment, passenger class, & median fare
ggplot(embark_fare, aes(x = Embarked, y = Fare, fill = factor(Pclass))) +
geom_boxplot() +
geom_hline(aes(yintercept=80),
colour='red', linetype='dashed', lwd=2) +
scale_y_continuous(labels=dollar_format()) +
theme_few()
# Since their fare was $80 for 1st class, they most likely embarked from 'C'
full$Embarked[c(62, 830)] <- 'C'
# Show row 1044
full[1044, ]
ggplot(full[full$Pclass == '3' & full$Embarked == 'S', ],
aes(x = Fare)) +
geom_density(fill = '#99d6ff', alpha=0.4) +
geom_vline(aes(xintercept=median(Fare, na.rm=T)),
colour='red', linetype='dashed', lwd=1) +
scale_x_continuous(labels=dollar_format()) +
theme_few()
# Replace missing fare value with median fare for class/embarkment
full$Fare[1044] <- median(full[full$Pclass == '3' & full$Embarked == 'S', ]$Fare, na.rm = TRUE)
# Show number of missing Age values
sum(is.na(full$Age))
# Make variables factors into factors
factor_vars <- c('PassengerId','Pclass','Sex','Embarked',
'Title','Surname','Family','FsizeD')
full[factor_vars] <- lapply(full[factor_vars], function(x) as.factor(x))
# Set a random seed
set.seed(129)
# Perform mice imputation, excluding certain less-than-useful variables:
mice_mod <- mice(full[, !names(full) %in% c('PassengerId','Name','Ticket','Cabin','Family','Surname','Survived')], method='rf')
# Save the complete output
mice_output <- complete(mice_mod)
# Plot age distributions
par(mfrow=c(1,2))
hist(full$Age, freq=F, main='Age: Original Data',
col='darkgreen', ylim=c(0,0.04))
hist(mice_output$Age, freq=F, main='Age: MICE Output',
col='lightgreen', ylim=c(0,0.04))
# Replace Age variable from the mice model.
full$Age <- mice_output$Age
# Show new number of missing Age values
sum(is.na(full$Age))
# First we'll look at the relationship between age & survival
ggplot(full[1:891,], aes(Age, fill = factor(Survived))) +
geom_histogram() +
# I include Sex since we know (a priori) it's a significant predictor
facet_grid(.~Sex) +
theme_few()
# Create the column child, and indicate whether child or adult
full$Child[full$Age < 18] <- 'Child'
full$Child[full$Age >= 18] <- 'Adult'
# Show counts
table(full$Child, full$Survived)
# Adding Mother variable
full$Mother <- 'Not Mother'
full$Mother[full$Sex == 'female' & full$Parch > 0 & full$Age > 18 & full$Title != 'Miss'] <- 'Mother'
# Show counts
table(full$Mother, full$Survived)
# Finish by factorizing our two new factor variables
full$Child  <- factor(full$Child)
full$Mother <- factor(full$Mother)
md.pattern(full)
# Split the data back into a train set and a test set
train <- full[1:891,]
test <- full[892:1309,]
# Set a random seed
set.seed(754)
# Build the model (note: not all possible variables are used)
rf_model <- randomForest(factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch +
Fare + Embarked + Title +
FsizeD + Child + Mother,
data = train)
# Show model error
plot(rf_model, ylim=c(0,0.36))
legend('topright', colnames(rf_model$err.rate), col=1:3, fill=1:3)
# Get importance
importance    <- importance(rf_model)
varImportance <- data.frame(Variables = row.names(importance),
Importance = round(importance[ ,'MeanDecreaseGini'],2))
# Create a rank variable based on importance
rankImportance <- varImportance %>%
mutate(Rank = paste0('#',dense_rank(desc(Importance))))
# Use ggplot2 to visualize the relative importance of variables
ggplot(rankImportance, aes(x = reorder(Variables, Importance),
y = Importance, fill = Importance)) +
geom_bar(stat='identity') +
geom_text(aes(x = Variables, y = 0.5, label = Rank),
hjust=0, vjust=0.55, size = 4, colour = 'red') +
labs(x = 'Variables') +
coord_flip() +
theme_few()
# Predict using the test set
prediction <- predict(rf_model, test)
# Save the solution to a dataframe with two columns: PassengerId and Survived (prediction)
solution <- data.frame(PassengerID = test$PassengerId, Survived = prediction)
# Write the solution to file
write.csv(solution, file = 'rf_mod_Solution.csv', row.names = F)
# Set a random seed
set.seed(754)
# Build the model (note: not all possible variables are used)
rf_model <- randomForest(factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch +
Fare + Embarked + Title +
FsizeD + Child + Mother,
data = train)
# Show model error
plot(rf_model, ylim=c(0,0.36))
legend('topright', colnames(rf_model$err.rate), col=1:3, fill=1:3)
library(caret)
set.seed(23)
training.rows <- createDataPartition(train$Survived,  p = 0.8, list = FALSE) #
train.batch <- train[training.rows, ]
test.batch <- train[-training.rows, ]
rf.grid <- data.frame(.mtry = c(2, 3))
cv.ctrl <- trainControl(method = "repeatedcv", repeats = 10,
summaryFunction = twoClassSummary,
classProbs = TRUE)
rf.tune <- train(Fate ~ Sex + Class + Age + Family + Embarked,
data = train.batch,
method = "rf",
metric = "ROC",
tuneGrid = rf.grid,
trControl = cv.ctrl)
rf.tune <- train(Survived ~ Pclass + Sex + Age + SibSp + Parch +
Fare + Embarked + Title +
FsizeD + Child + Mother,
data = train.batch,
method = "rf",
metric = "ROC",
tuneGrid = rf.grid,
trControl = cv.ctrl)
train.batch
rf.tune <- train(Survived ~ Pclass + Sex + Age + SibSp + Parch +
Fare + Embarked + Title +
FsizeD + Child + Mother,
data = train.batch,
method = "rf",
metric = "ROC",
tuneGrid = rf.grid,
trControl = cv.ctrl)
train$Survived <- revalue(train$Survived, c("1" = "Survived", "0" = "Perished"))
train$Survived <- revalue(train$Survived, c("1" = "Survived", "0" = "Perished"))
data$Fate <- revalue(data$Fate, c("1" = "Survived", "0" = "Perished"))
str(train)
cv.ctrl <- trainControl(method = "repeatedcv", repeats = 10,
summaryFunction = twoClassSummary,
classProbs = TRUE)
rf.grid <- data.frame(.mtry = c(2, 3))
rf.tune <- train(Survived ~ Pclass + Sex + Age + SibSp + Parch +
Fare + Embarked + Title +
FsizeD + Child + Mother,
data = train.batch,
method = "rf",
metric = "ROC",
tuneGrid = rf.grid,
trControl = cv.ctrl)
train$Survived <- revalue(train$Survived, c("1" = "Survived", "0" = "Perished"))
train[Survived] <- lapply(Survived, function(x) as.factor(x))
train[Survived] <- lapply(train$Survived, function(x) as.factor(x))
rf.tune <- train(factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch +
Fare + Embarked + Title +
FsizeD + Child + Mother,
data = train.batch,
method = "rf",
metric = "ROC",
tuneGrid = rf.grid,
trControl = cv.ctrl)
library(Rserve)
install.packages("Rserve")
library(Rserve)
Rserve()
Rserve() --vanilla
Rserve(vanilla)
tableau.data.file <- "tableau.csv"
rm(list = ls())
readData <- function(path.name, file.name, column.types, missing.types) {
read.csv( url( paste(path.name, file.name, sep="") ),
colClasses=column.types,
na.strings=missing.types )
}
Titanic.path <- "https://raw.github.com/wehrley/Kaggle_Titanic/master/"
train.data.file <- "train.csv"
test.data.file <- "test.csv"
tableau.data.file <- "tableau.csv"
missing.types <- c("NA", "")
train.column.types <- c('integer',   # PassengerId
'factor',    # Survived
'factor',    # Pclass
'character', # Name
'factor',    # Sex
'numeric',   # Age
'integer',   # SibSp
'integer',   # Parch
'character', # Ticket
'numeric',   # Fare
'character', # Cabin
'factor'     # Embarked
)
test.column.types <- train.column.types[-2]     # # no Survived column in test.csv
train.raw <- readData(Titanic.path, train.data.file,
train.column.types, missing.types)
df.train <- train.raw
test.raw <- readData(Titanic.path, test.data.file,
test.column.types, missing.types)
df.infer <- test.raw
tab <- read.csv('../input/tableau.csv', stringsAsFactors = F)
str(tab)
str(train)
str(train)
str(tab)
full  <- bind_rows(train, test) # bind training & test data
rm(list = ls())
train <- read.csv('../input/train.csv', stringsAsFactors = F)
test  <- read.csv('../input/test.csv', stringsAsFactors = F)
tab <- read.csv('../input/tableau.csv', stringsAsFactors = F)
str(tab)
full  <- bind_rows(train, test) # bind training & test data
# check data
str(full)
View(tab)
summary(tab)
